# Satta Result Scraper

An automated web scraper that collects results from spboss.in every 6 hours and stores them in Supabase.

## Features

- Automatic scraping every 6 hours
- Data storage in Supabase
- RESTful API endpoints
- Historical data tracking

## Prerequisites

1. Node.js (v14 or higher)
2. npm or yarn
3. A Supabase account (free tier works)

## Installation Steps

1. **Clone or download the project**
   ```bash
   git clone <repository-url>
   # or download and extract the ZIP file
   ```

2. **Install dependencies**
   ```bash
   cd project-directory
   npm install
   ```

3. **Set up Supabase**
   - Create a new project at https://supabase.com
   - Go to SQL Editor in your Supabase dashboard
   - Run this SQL to create the required table:
   ```sql
   -- Create the scrape_results table
   create table if not exists public.scrape_results (
       id bigint generated by default as identity primary key,
       scraped_at timestamp with time zone not null default now(),
       data jsonb not null,
       created_at timestamp with time zone not null default now()
   );

   -- Enable RLS and set policies
   alter table public.scrape_results enable row level security;

   -- Create policy for anonymous access
   create policy "Allow all operations for anonymous users"
       on public.scrape_results
       for all
       to anon
       using (true)
       with check (true);
   ```

4. **Configure environment variables**
   - Copy the `.env.example` file to `.env`
   - Update with your Supabase credentials:
   ```
   SUPABASE_URL=your_supabase_project_url
   SUPABASE_ANON_KEY=your_supabase_anon_key
   ```

## Running Locally

1. **Start the server**
   ```bash
   npm start
   ```

2. **Access the endpoints**
   - Health check: `http://localhost:3001/`
   - Get latest results: `http://localhost:3001/scrape`
   - View history: `http://localhost:3001/history`
   - Check update status: `http://localhost:3001/status`

## Deployment Options

### 1. Deploy on Railway.app (Recommended)
1. Create an account on Railway.app
2. Connect your GitHub repository
3. Add environment variables in Railway dashboard
4. Deploy the project

### 2. Deploy on Heroku
1. Install Heroku CLI
2. Login to Heroku
   ```bash
   heroku login
   ```
3. Create a new Heroku app
   ```bash
   heroku create your-app-name
   ```
4. Set environment variables
   ```bash
   heroku config:set SUPABASE_URL=your_supabase_url
   heroku config:set SUPABASE_ANON_KEY=your_supabase_anon_key
   ```
5. Deploy
   ```bash
   git push heroku main
   ```

### 3. Deploy on VPS (DigitalOcean, AWS, etc.)
1. SSH into your server
2. Install Node.js and npm
3. Clone the repository
4. Install PM2 globally
   ```bash
   npm install -g pm2
   ```
5. Start the application
   ```bash
   pm2 start index.js --name "satta-scraper"
   ```
6. Setup PM2 to start on boot
   ```bash
   pm2 startup
   pm2 save
   ```

## API Documentation

### GET /
Health check endpoint
```json
{
    "status": "Server is running",
    "last_update": "timestamp",
    "next_update": "timestamp"
}
```

### GET /scrape
Trigger manual scrape and get latest results
```json
{
    "success": true,
    "data": {
        "results": [
            {
                "market_name": "MARKET NAME",
                "full_number": "599-39-568",
                "numbers": {
                    "open": "599",
                    "jodi": "39",
                    "close": "568"
                }
            }
        ]
    }
}
```

### GET /history
Get last 10 scrape results
```json
{
    "success": true,
    "data": [/* array of historical records */]
}
```

### GET /status
Check update status
```json
{
    "success": true,
    "last_update": "timestamp",
    "next_update": "timestamp",
    "update_interval_hours": 6
}
```

## Maintenance

- Monitor the logs for any errors
- Check Supabase dashboard for data storage
- Verify automatic updates are running using the /status endpoint

## Troubleshooting

1. If scraping fails:
   - Check if the website structure has changed
   - Verify your IP isn't blocked
   - Check Puppeteer logs

2. If database operations fail:
   - Verify Supabase credentials
   - Check RLS policies
   - Monitor Supabase quotas

3. If automatic updates stop:
   - Check server logs
   - Verify the process hasn't crashed
   - Restart the application

## Support

For issues and feature requests, please create an issue in the repository. 